Valeu pelo retorno â€” bora fechar isso de forma objetiva.

O que estÃ¡ acontecendo (pelos seus prints)

Chat duplica a mesma fala â†’ duas chamadas do frontend (ou StrictMode), mas deixo um guard no backend tambÃ©m.

Sem produtos em â€œquero o 12 / iphone 12â€ â†’ sua busca estÃ¡ â€œduraâ€: nÃ£o entende contexto (â€œ12â€ depois de â€œiphoneâ€) e o match nÃ£o Ã© tolerante (acentos, variaÃ§Ãµes, palavras extras).

IA volta a perguntar cidade/preÃ§o â†’ quando ela nÃ£o â€œvÃªâ€ produtos, tenta interrogar.

O que vou mudar (sem engessar a IA)

Busca inteligente (robusta): normaliza acentos, pontuaÃ§Ã£o, tokeniza e faz match por tokens/numero; entende que â€œquero o 12â€ depois de â€œiphoneâ€ = â€œiphone 12â€.

MemÃ³ria curta de contexto por sessÃ£o: guarda Ãºltimo foco (â€œiphoneâ€, â€œperfumesâ€, â€œdroneâ€).

Prefetch com â€œquery finalâ€ (mensagem + contexto), entÃ£o a IA vÃª produtos e nÃ£o interroga.

SanitizaÃ§Ã£o total do chat (sem links/imagens) e fala curta.

Guard anti-dupla-chamada no backend (idempotÃªncia simples).

Abaixo, patches pequenos (substitua sÃ³ estes trechos).

1) src/services/catalog.js â€” busca robusta
// src/services/catalog.js
// âœ… mantenha seu CATALOGO real; deixo aqui a busca mais inteligente.

const normalize = (s="") =>
  s.normalize("NFD").replace(/[\u0300-\u036f]/g, "").toLowerCase();

const tokenize = (s="") =>
  normalize(s).replace(/[^a-z0-9\s]/g, " ").split(/\s+/).filter(Boolean);

/**
 * Busca tolerante por tokens (inclui nÃºmeros: "12", "128").
 * Retorna itens casados por tÃ­tulo/marca/categoria.
 */
export async function buscarOfertas({ query, maxResultados = 12 } = {}) {
  const q = String(query || "").trim();
  if (!q) return [];

  const qTokens = tokenize(q);
  if (qTokens.length === 0) return [];

  // mapeie para seus campos reais
  const fields = (p) => [
    p.titulo || "",
    p.marca || "",
    p.categoria || ""
  ].map(normalize).join(" ");

  // score: +2 para token que aparece inteiro, +1 para nÃºmero parcial
  const score = (prod) => {
    const hay = fields(prod);
    let s = 0;
    for (const t of qTokens) {
      if (!t) continue;
      if (hay.includes(` ${t} `) || hay.startsWith(t+" ") || hay.endsWith(" "+t) || hay === t) s += 2;
      else if (/^\d+$/g.test(t) && hay.includes(t)) s += 1; // nÃºmeros dentro do texto
    }
    return s;
  };

  const ranked = (globalThis.CATALOGO || []).map(p => ({ p, s: score(p) }))
    .filter(x => x.s > 0)
    .sort((a,b) => (b.s - a.s) || ((a.p.preco ?? 0) - (b.p.preco ?? 0)))
    .slice(0, Math.max(1, Math.min(50, maxResultados)))
    .map(x => x.p);

  return ranked;
}

// Exporte CATALOGO se vocÃª estiver usando mock aqui.
// export const CATALOGO = [ ... ];


Essa busca entende â€œiphone 12â€, â€œquero o 12â€ (se for combinado com contexto), â€œ128â€, e ignora acentos/maiusc./pontuaÃ§Ã£o.

2) src/ai/chat.js â€” contexto + prefetch + fala curta
// src/ai/chat.js
import { openai } from "./openai.js";
import { buscarOfertas } from "../services/catalog.js";

// memÃ³ria curta em processo (por sessÃ£o)
const ctx = new Map(); // sessionId -> { foco: "iphone" }

const SYSTEM_STYLE = `
VocÃª Ã© o Assistente de Compras do Click Ofertas.
Tom natural, bem-humorado (mÃ¡x 1 emoji), Ãºtil.
No chat: nÃ£o cole links/URLs/imagens e nÃ£o liste catÃ¡logos; use no mÃ¡x 2 frases.
Mostre primeiro: nunca bloqueie pedindo cidade/preÃ§o; faÃ§a no mÃ¡x 1 pergunta leve DEPOIS de mostrar algo.
`.trim();

const clean = (t="") => String(t)
  .replace(/!\[[^\]]*]\([^)]+\)/g,"")
  .replace(/\[([^\]]+)]\(([^)]+)\)/g,"$1")
  .replace(/https?:\/\/\S+/g,"")
  .replace(/\s{2,}/g," ")
  .trim();

// inferir foco simples (marca/categoria) para memÃ³ria
const focoFrom = (msg="") => {
  const m = msg.toLowerCase();
  if (/\biphone|apple\b/.test(m)) return "iphone";
  if (/\bgalaxy|samsung\b/.test(m)) return "samsung";
  if (/\bperfume(s)?\b/.test(m)) return "perfume";
  if (/\bdrone(s)?\b/.test(m)) return "drone";
  return null;
};

// monta query final combinando contexto + mensagem curta (ex.: "quero o 12" => "iphone 12")
function buildFinalQuery(message, focoPrev) {
  const msg = message.trim();
  const hasBrandWord = /\b(iphone|apple|samsung|galaxy|drone|perfume)\b/i.test(msg);
  const hasNumber = /\b\d{2,4}\b/.test(msg); // 12, 128, 256, 2024 etc.

  if (!hasBrandWord && hasNumber && focoPrev) {
    return `${focoPrev} ${msg}`;  // exemplo: "iphone 12"
  }
  return msg; // caso geral
}

export async function chatOnce({ message, sessionId="anon" }) {
  const focoNovo = focoFrom(message);
  const focoPrev = ctx.get(sessionId)?.foco || focoNovo || focoFrom("");// fallback nulo
  if (focoNovo) ctx.set(sessionId, { foco: focoNovo });

  const finalQuery = buildFinalQuery(message, focoPrev);

  // PREFETCH: sempre busca com a "finalQuery"
  const ofertas = await buscarOfertas({ query: finalQuery, maxResultados: 12 });

  // escolhe frase-base
  let base;
  if (ofertas.length > 0) {
    // genÃ©rico ou especÃ­fico
    const tokens = finalQuery.trim().split(/\s+/);
    const segmento = (focoPrev || focoNovo || /iphone|apple/i.test(finalQuery) ? "aparelhos da Apple"
                    : /samsung|galaxy/i.test(finalQuery) ? "aparelhos Samsung"
                    : /drone/i.test(finalQuery) ? "drones"
                    : /perfume/i.test(finalQuery) ? "perfumes"
                    : "esses produtos");
    base = (tokens.length <= 2)
      ? `Vejo que vocÃª estÃ¡ de olho em ${segmento}. Listei alguns modelos abaixo. Me diga qual vocÃª quer! ğŸ˜‰`
      : `Achei opÃ§Ãµes e deixei nos resultados abaixo. Quer que eu afine por variaÃ§Ã£o/modelo?`;
  } else {
    base = `NÃ£o encontrei itens com esse termo. Me diga o modelo exato que vocÃª quer ver ğŸ™‚`;
  }

  // SÃ³ uso o modelo para lapidar tom (sem tools, sem interrogatÃ³rio)
  const completion = await openai.chat.completions.create({
    model: process.env.CHAT_MODEL || "gpt-4o-mini",
    temperature: 0.4,
    messages: [
      { role: "system", content: SYSTEM_STYLE },
      { role: "user", content: `Reescreva em 1â€“2 frases, sem links/imagens: "${base}"` }
    ]
  });

  const text = clean(completion.choices?.[0]?.message?.content || base);

  return { text, ofertas };
}


O que isso resolve:

â€œquero o 12â€ logo apÃ³s â€œiphoneâ€ vira query â€œiphone 12â€ â†’ encontra.

â€œiphone 12â€ com variaÃ§Ãµes/acentos/palavras extras â†’ match por tokens/numero encontra.

IA nÃ£o entra em interrogatÃ³rio porque sempre mostramos algo (ou um caminho) e lapidamos o texto sem permitir tools nesse turno.

Sem links/imagens no chat (sanitizaÃ§Ã£o).

Fala sempre curta.

3) (Opcional) Guard anti-duplicidade no backend
// server.js â€” antes das rotas
const recent = new Set();
setInterval(()=>recent.clear(), 3000);

// na rota /ai/chat
app.post("/ai/chat", async (req,res)=>{
  const key = JSON.stringify({ m:req.body?.message, s:req.body?.sessionId });
  if (recent.has(key)) return res.json({ text: "", ofertas: [] }); // ou ignore
  recent.add(key);
  // ... segue chatOnce
});

Teste esperado

â€œiphoneâ€ â†’ mostra iPhones no painel; chat curto + pergunta leve.

â€œquero o 12â€ â†’ usa contexto e mostra iPhone 12 (sem ficar genÃ©rico).

â€œiphone 12â€ â†’ lista no painel; chat curto; nada de link.

â€œdroneâ€ / â€œperfumesâ€ â†’ mostra itens; pergunta leve sÃ³ depois.

SilÃªncio do usuÃ¡rio â†’ o assistente continua ajudando; nunca trava pedindo cidade/preÃ§o.