C√ìDIGO COMPLETO DA IA DO CLICK OFERTAS - ONDE EST√ÉO OS PROBLEMAS
==================================================================

ARQUIVO: server/routes.ts (Se√ß√£o de Streaming da IA - Linhas 6950-7450)
-------------------------------------------------------------------------

// ============================================================================
// ü§ñ STREAMING AI ASSISTANT - Sistema Principal de IA
// ============================================================================

app.post('/api/assistant/stream', async (req: any, res) => {
  try {
    const { message, sessionId } = req.body;
    const user = req.user || req.session?.user;

    console.log(`ü§ñ [assistant/stream] Nova mensagem: "${message}" para sessionId: ${sessionId}`);

    if (!message?.trim()) {
      res.status(400).json({ success: false, message: 'Message is required' });
      return;
    }

    // Get or create session
    let session = await storage.getAssistantSession(sessionId);
    if (!session) {
      session = await storage.createAssistantSession({
        id: sessionId,
        userId: user?.id || null,
        metadata: { createdAt: new Date().toISOString() },
      });
    }

    // Get user name for personalization
    let name = 'Cliente';
    if (user?.id) {
      try {
        const userData = await storage.getUser(user.id);
        if (userData?.firstName) {
          name = userData.firstName;
          if (userData.lastName) {
            name += ` ${userData.lastName}`;
          }
        }
      } catch (error) {
        console.warn('Could not fetch user name:', error);
      }
    }

    // Salvar mensagem do usu√°rio ANTES de processar
    await storage.createAssistantMessage({
      sessionId,
      content: message,
      role: 'user',
      metadata: { timestamp: new Date().toISOString() },
    });

    // Buscar hist√≥rico de mensagens para contexto
    const sessionWithMessages = await storage.getAssistantSessionWithMessages(sessionId);
    const recentMessages = (sessionWithMessages?.messages || [])
      .slice(-6) // √öltimas 6 mensagens para contexto
      .map(msg => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      }));

    // üÜî ANTI-CORRIDA: Gerar requestId √∫nico
    const requestId = `${Date.now()}-${Math.random().toString(36).slice(2,8)}`;
    
    // üîß Headers SSE corretos + flush (sem compress√£o)
    res.setHeader("Content-Type", "text/event-stream; charset=utf-8");
    res.setHeader("Cache-Control", "no-cache, no-transform");
    res.setHeader("Connection", "keep-alive");
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.setHeader('Access-Control-Allow-Headers', 'Content-Type');
    res.flushHeaders?.();
    
    const SSE_COMPAT = false; // ‚ùå DESLIGADO PARA EVITAR DUPLICA√á√ÉO
    
    function send(event: string, payload: any) {
      res.write(`event: ${event}\n`);
      res.write(`data: ${JSON.stringify(payload)}\n\n`);
    }
    
    // ‚ö†Ô∏è Compatibilidade com chamadas antigas:
    function write(obj: any) {
      const event = obj?.type ?? 'delta';
      if (event === 'delta' && obj.text) {
        send(event, { ...obj, requestId, seq: ++deltaSeq });
      } else {
        send(event, { ...obj, requestId });
      }
    }
    
    // Contador de sequ√™ncia para dedupe
    let deltaSeq = 0;
    
    // Enviar meta + delta imediato para destravar UI
    send('meta', { requestId });
    send('delta', { requestId, text: 'Beleza! J√° confiro essas ofertas‚Ä¶ üòâ', seq: ++deltaSeq });

    // üîí WATCHDOG: Fail-safe para garantir presen√ßa de conte√∫do
    let lastDelta = Date.now();
    let watchdog: NodeJS.Timeout | null = null;
    watchdog = setInterval(() => {
      if (Date.now() - lastDelta > 7000) {
        console.log(`‚è∞ [assistant/stream] Watchdog ativado - enviando fallback ap√≥s 7s sem conte√∫do`);
        write({ type: 'delta', text: '\n(um instante‚Ä¶ garimpando ofertas) ' });
        lastDelta = Date.now();
      }
    }, 7000);

    // Limpar watchdog quando request for fechado
    req.on('close', () => {
      console.log(`üßπ [assistant/stream] Request fechado - limpando watchdog`);
      if (watchdog) { clearInterval(watchdog); watchdog = null; }
    });

    // Fun√ß√£o helper para atualizar lastDelta
    const writeWithHeartbeat = (data: any) => {
      if (data.type === 'delta') lastDelta = Date.now();
      send(data.type || 'delta', data);
    };
    
    // Fun√ß√£o para finalizar stream
    async function finish() {
      if (watchdog) { clearInterval(watchdog); watchdog = null; }
      write({ type: 'complete' });
      res.end();
    }

    // üß† DETEC√á√ÉO DE INTEN√á√ÉO antes da busca
    console.log(`üé¨ [assistant/stream] Processando: "${message}" para usu√°rio: ${name}`);
    
    const { buildGrounding, composePrompts, detectIntent } = await import('./lib/answerComposer.js');
    const intent = detectIntent(message);
    
    console.log(`üß† [assistant/stream] Inten√ß√£o detectada: ${intent}`);
    
    // üé™ SMALL TALK: Resposta direta sem busca de produtos
    if (intent === 'SMALL_TALK') {
      console.log(`üí¨ [assistant/stream] Small talk detectado - resposta direta`);
      
      const smallTalkSystem = `Voc√™ √© o "Clique", consultor virtual do Click Ofertas. Seja simp√°tico, breve e humano. Responda √† pergunta pessoal feita pelo usu√°rio de forma natural e encaminhe para ajudar com compras. Use humor leve e emoji ocasional.`;
      
      // ‚ùå PROBLEMA: STREAMING REAL REMOVIDO - AQUI DEVERIA TER O LOOP
      const stream = await clickClient.chat.completions.create({
        model: process.env.CHAT_MODEL || 'gpt-4o-mini',
        messages: [
          { role: 'system', content: smallTalkSystem },
          { role: 'user', content: message }
        ],
        temperature: 0.7,
        max_tokens: 150,
        stream: true
      });

      let fullText = 'Conversa casual simulada'; // ‚ùå HARDCODED AQUI
      
      await storage.createAssistantMessage({ 
        sessionId, 
        content: fullText, 
        role:'assistant', 
        metadata:{ 
          streamed: true, 
          intent: 'SMALL_TALK',
          noProductSearch: true,
          requestId
        } 
      });
      
      console.log(`üèÅ [assistant/stream] Small talk finalizado - enviando complete`);
      await finish();
      return; // ‚ö†Ô∏è EARLY RETURN - N√ÉO CONTINUA PARA BUSCA
    }
    
    // ‚ù∂ RAG melhorado: busca produtos apenas para SEARCH e MORE
    // üîß CORRE√á√ÉO: origin com x-forwarded headers para proxy/CDN
    const proto = req.get('x-forwarded-proto') || req.protocol;
    const host = req.get('x-forwarded-host') || req.get('host');
    const origin = `${proto}://${host}`;
    const ground = await buildGrounding(origin, message, sessionId);
    
    console.log(`üìä [assistant/stream] Resultado buildGrounding:`, {
      all: ground.all.length,
      top3: ground.top3.length,
      top8: ground.top8.length
    });
    
    // ‚ùÇ Sistema de aprendizado: registrar busca do usu√°rio
    try {
      await storage.createSearchLog({
        sessionId,
        userId: user?.id || null,
        query: message.toLowerCase().trim(),
        foundProducts: ground.all.length,
        timestamp: new Date(),
        metadata: { 
          hasMultipleStores: new Set(ground.all.map(p => p.storeName).filter(Boolean)).size > 1,
          categories: [...new Set(ground.all.map(p => p.category).filter(Boolean))]
        }
      });
    } catch (error) {
      console.warn('Erro ao registrar busca para aprendizado:', error);
    }
    
    // üß† INTELIG√äNCIA DE VENDAS: gerar recomenda√ß√µes autom√°ticas se h√° produto em foco
    let focusedProduct = null;
    let recommendations = null;
    
    if (ground.contextType === 'focused_product' && ground.sessionMemory?.currentFocusProductId) {
      const focusId = ground.sessionMemory.currentFocusProductId;
      focusedProduct = ground.sessionMemory.lastShownProducts?.find(p => p.id === focusId);
      
      if (focusedProduct) {
        console.log(`üéØ [assistant/stream] Produto em foco detectado: "${focusedProduct.title}"`);
        
        // Importar sistema de recomenda√ß√µes
        const { getProductRecommendations } = await import('./lib/tools.js');
        
        try {
          recommendations = await getProductRecommendations(focusedProduct);
          console.log(`üí° [assistant/stream] Recomenda√ß√µes geradas:`, {
            upsells: recommendations.upsells?.length || 0,
            crossSells: recommendations.crossSells?.length || 0,
            total: recommendations.all?.length || 0
          });
        } catch (error) {
          console.error('‚ùå [assistant/stream] Erro ao gerar recomenda√ß√µes:', error);
          recommendations = { upsells: [], crossSells: [], all: [] };
        }
      }
    }

    const promptResult = composePrompts({
      q: message, name, top3: ground.top3, top8: ground.top8,
      focusedProduct, recommendations
    });
    
    const { SYSTEM, USER, productSet, requiresJsonOutput } = promptResult;
    
    console.log(`üí≠ [assistant/stream] Prompts gerados:`, {
      systemLength: SYSTEM.length,
      userLength: USER.length,
      hasProducts: productSet?.length > 0,
      requiresJson: !!requiresJsonOutput,
      productSetIds: productSet?.map(p => p.id) || []
    });

    // üîß POL√çTICA SEM CAT√ÅLOGO = SEM RESPOSTA DE PRODUTO
    if (!productSet || productSet.length === 0) {
      console.log(`‚ö†Ô∏è [assistant/stream] ProductSet vazio - enviando apenas mensagem de refinamento`);
      
      // üîß CORRE√á√ÉO: Mensagem melhorada com tom vendedor Clique
      const refinementMessage = "N√£o achei itens agora. Me diz **categoria** (drone, perfume) e **or√ßamento** que eu garimpo ofertas boas para voc√™! üòâ";
      
      // Enviar mensagem com streaming
      write({ type:'delta', text: refinementMessage });
      
      await storage.createAssistantMessage({ 
        sessionId, 
        content: refinementMessage, 
        role:'assistant', 
        metadata:{ 
          streamed: true, 
          hardGrounding: true, 
          productSetEmpty: true 
        } 
      });
      
      console.log(`üèÅ [assistant/stream] Cat√°logo vazio finalizado - enviando complete`);
      write({ type:'complete' });
      res.end();
      return;
    }

    // ‚ù∑ Construir mensagens com hist√≥rico para mem√≥ria
    const messages = [
      { role:'system' as const, content: SYSTEM },
      // Incluir mensagens anteriores para contexto (excluindo a atual que j√° foi salva)
      ...recentMessages.slice(0, -1),
      { role:'user' as const, content: USER }
    ];

    // ‚ùÉ Hard Grounding: LLM deve retornar JSON estruturado
    let llmResponse = '';
    
    if (requiresJsonOutput) {
      console.log(`üîß [assistant/stream] Usando STREAMING REAL com Hard Grounding`);
      
      // üìù PERSONA INTERATIVA - Sistema que sempre engaja
      const interactiveSystem = `Voc√™ √© o "Clique", consultor do Click Ofertas.

REGRAS CR√çTICAS:
1) NUNCA mencione pre√ßos, nomes de lojas, ou links na sua resposta
2) Seja CONCISO: m√°ximo 1-2 frases curtas
3) Se houver produtos: diga apenas "Encontrei v√°rias op√ß√µes de [produto]. Listei abaixo as melhores!"
4) Se sem produtos: pe√ßa refinamento em 1 frase simples
5) Para conversas: apresente-se como "Clique, seu consultor de ofertas!"

M√ÅXIMO: 80 caracteres. SEM pre√ßos/lojas/links.`;

      // ‚ö° STREAMING: Resposta em tempo real
      // ‚ùå PROBLEMA CR√çTICO: STREAMING LOOP REMOVIDO!!!
      const streamResponse = await clickClient.chat.completions.create({
        model: process.env.CHAT_MODEL || 'gpt-4o-mini',
        messages: [
          { role:'system', content: interactiveSystem },
          ...recentMessages.slice(0, -1),
          { role:'user', content: USER }
        ],
        stream: true,
        temperature: 0.7,
        max_tokens: 250
      });

      let fullStreamText = 'Resposta interativa simulada'; // ‚ùå HARDCODED AQUI
      
      llmResponse = fullStreamText;
      write({ type: 'paragraph_done' });
      
      // üîß JSON ESTRUTURADO: Gerar separadamente para valida√ß√£o
      const jsonResponse = await clickClient.chat.completions.create({
        model: process.env.CHAT_MODEL || 'gpt-4o-mini',
        messages: [
          { role: 'system', content: `IMPORTANTE: Retorne JSON v√°lido no formato EXATO:
{
  "items": [
    {"id": "produto_id", "why": "raz√£o curta"}
  ],
  "message": "texto da resposta"
}

Use somente estes IDs v√°lidos: ${productSet.map(p => p.id).slice(0,3).join(', ')}...

JAMAIS use "produtos", "nome" ou outros campos. Sempre "items" e "why".` },
          { role: 'user', content: `Produtos mencionados na conversa: "${llmResponse}"

IDs v√°lidos:
${productSet.map(p => `- ${p.id}: ${p.title}`).slice(0,3).join('\n')}...` }
        ],
        temperature: 0.1,
        max_tokens: 200
      });

      const rawJson = jsonResponse.choices[0].message.content;
      console.log(`üì¶ [assistant/stream] JSON estruturado gerado:`, rawJson);

      try {
        const parsedResponse = JSON.parse(rawJson || '{}');
        const { items = [], message = '' } = parsedResponse;
        
        // üîß VALIDA√á√ÉO SERVIDOR-SIDE: s√≥ aceitar IDs do productSet
        const allowedIds = new Set(productSet.map(p => p.id));
        const validItems = items.filter(item => allowedIds.has(item.id));
        
        console.log(`‚úÖ [assistant/stream] Valida√ß√£o JSON com Streaming:`, {
          itemsReceived: items.length,
          validItems: validItems.length,
          allowedIds: [...allowedIds],
          receivedIds: items.map(i => i.id),
          streamedText: fullStreamText.length
        });
        
        // ‚ùπ Enviar produtos validados com metadados enriquecidos
        if (validItems.length > 0) {
          const enrichedProducts = validItems.map(item => {
            const product = productSet.find(p => p.id === item.id);
            if (!product) return null;
            
            // Validar upsellIds tamb√©m
            const validUpsells = (item.upsellIds || [])
              .filter(upsellId => allowedIds.has(upsellId))
              .map(upsellId => productSet.find(p => p.id === upsellId))
              .filter(Boolean);
            
            return {
              ...product,
              name: product.title,
              reason: item.reason || 'Produto recomendado',
              upsells: validUpsells,
              cliqueRecommended: true // Marca da nova persona
            };
          }).filter(Boolean);
          
          console.log(`üì¶ [assistant/stream] Enviando ${enrichedProducts.length} produtos do Clique:`, {
            withReasons: enrichedProducts.filter(p => p.reason).length,
            withUpsells: enrichedProducts.filter(p => p.upsells.length > 0).length
          });
          
          write({ 
            type: 'products', 
            products: enrichedProducts,
            query: message,
            validationApplied: true,
            hardGrounding: true,
            cliquePersona: true,
            schemaVersion: 2
          });
        } else {
          console.log(`‚ö†Ô∏è [assistant/stream] Nenhum produto v√°lido ap√≥s valida√ß√£o`);
        }
        
      } catch (error) {
        console.error(`‚ùå [assistant/stream] Erro ao parsear JSON do LLM:`, error);
        console.log(`üîß [assistant/stream] JSON bruto que falhou:`, rawJson);
        
        // üöë FALLBACK: usar produtos do productSet mesmo com JSON quebrado
        const fallbackProducts = productSet.slice(0, 3).map(product => ({
          ...product,
          name: product.title,
          reason: 'Produto selecionado pelo Clique',
          upsells: [],
          cliqueRecommended: true
        }));
        
        console.log(`üöë [assistant/stream] Usando fallback com ${fallbackProducts.length} produtos`);
        
        write({ 
          type: 'products', 
          products: fallbackProducts,
          query: llmResponse,
          validationApplied: false,
          hardGrounding: true, // Ainda usa produtos reais
          jsonParseFailed: true,
          schemaVersion: 2
        });
      }
      
    } else {
      // ‚ù∏ Fallback: modo antigo (n√£o deveria ser usado mais)
      console.log(`‚ö†Ô∏è [assistant/stream] Usando modo antigo (n√£o recomendado)`);
      
      const stream = await clickClient.chat.completions.create({
        model: process.env.CHAT_MODEL || 'gpt-4o-mini',
        messages,
        temperature: 0.15,
        max_tokens: 220,
        frequency_penalty: 0.3,
        presence_penalty: 0.0,
        stream: true
      });

      let full='Resumo gerado'; const LIMIT=600; // ‚ùå HARDCODED AQUI
      
      write({ type:'chunk', text: full });
      
      llmResponse = full;
      
      // Enviar produtos do modo antigo
      const productsToSend = (ground.top8?.length > 0 ? ground.top8 : ground.top3 || []).map(product => ({
        ...product,
        name: product.title,
      }));
      
      if (productsToSend.length > 0) {
        write({ 
          type: 'products', 
          products: productsToSend,
          query: message,
          focusedProduct,
          recommendations,
          hardGrounding: false
        });
      }
    }
    
    // Simular salvamento de mensagem
    console.log('üìù [assistant/stream] Mensagem criada (simulada)');
    
    // Garantir que h√° conte√∫do antes de finalizar
    if (!llmResponse || llmResponse.trim().length === 0) {
      console.log(`‚ö†Ô∏è [assistant/stream] Sem conte√∫do - enviando mensagem m√≠nima`);
      const fallbackText = "Encontrei algumas op√ß√µes para voc√™! üòä";
      write({ type:'delta', text: fallbackText });
    }
    
    console.log(`üèÅ [assistant/stream] Streaming principal finalizado - enviando complete`);
    
    // üßπ LIMPAR WATCHDOG antes de finalizar
    if (watchdog) { clearInterval(watchdog); watchdog = null; }
    
    write({ type:'complete' }); 
    res.end();
  } catch (e) {
    console.error('stream', e);
    if (watchdog) { clearInterval(watchdog); watchdog = null; } // üßπ Limpar watchdog em caso de erro
    res.write(`data: ${JSON.stringify({ type:'error', message:'stream error' })}\n\n`); res.end();
  }
});

==================================================================
PROBLEMAS IDENTIFICADOS:
==================================================================

1. ‚ùå STREAMING LOOPS REMOVIDOS:
   - As linhas de processamento dos chunks do OpenAI foram removidas
   - S√≥ h√° cria√ß√£o do stream, mas n√£o consumo dos dados
   - Texto fica hardcoded como "Conversa casual simulada", etc.

2. ‚ùå FALTA DO SISTEMA buscarOfertas:
   - N√£o existe tool call para buscarOfertas
   - OpenAI n√£o consegue chamar fun√ß√µes externas
   - N√£o h√° sistema de tool_calls configurado

3. ‚ùå RESPONSES TRUNCADAS:
   - Quando h√° stream.choices[0].message.content, n√£o h√° loop para ler chunks
   - S√≥ pega o primeiro chunk e para

4. ‚ùå AUS√äNCIA DE TOOL SYSTEM:
   - Falta configura√ß√£o de functions/tools na chamada do OpenAI
   - Falta handler para quando OpenAI quer chamar buscarOfertas

==================================================================
SOLU√á√ÉO NECESS√ÅRIA:
==================================================================

1. ‚úÖ RESTAURAR LOOPS DE STREAMING:
```javascript
for await (const chunk of stream) {
  const delta = chunk.choices[0]?.delta;
  if (delta?.content) {
    fullText += delta.content;
    write({ type: 'delta', text: delta.content });
  }
}
```

2. ‚úÖ ADICIONAR TOOL SYSTEM:
```javascript
const stream = await clickClient.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [...],
  tools: [{
    type: "function",
    function: {
      name: "buscarOfertas",
      description: "Busca produtos e ofertas no cat√°logo",
      parameters: {
        type: "object",
        properties: {
          query: { type: "string" },
          categoria: { type: "string" }
        }
      }
    }
  }],
  tool_choice: "auto",
  stream: true
});
```

3. ‚úÖ HANDLER PARA TOOL CALLS:
```javascript
for await (const chunk of stream) {
  const delta = chunk.choices[0]?.delta;
  
  if (delta?.tool_calls) {
    // Handle function call
    const toolCall = delta.tool_calls[0];
    if (toolCall?.function?.name === 'buscarOfertas') {
      const args = JSON.parse(toolCall.function.arguments);
      const searchResults = await searchSuggestions(args.query);
      
      // Continue stream with tool result
      stream.inputs.append({
        role: "tool",
        name: "buscarOfertas", 
        content: JSON.stringify(searchResults)
      });
    }
  }
  
  if (delta?.content) {
    write({ type: 'delta', text: delta.content });
  }
}
```

==================================================================
ARQUIVO: client/src/hooks/use-assistant-chat.ts (Frontend - Anti-Race)
==================================================================

// Prote√ß√µes implementadas no frontend para evitar duplica√ß√£o:
// - Dedupe por sequ√™ncia
// - RequestId tracking  
// - fetchSuggest guards
// - Content-Type validation

[Consulte o arquivo completo para detalhes do frontend]